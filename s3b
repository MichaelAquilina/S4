#! /usr/bin/env python

import argparse
import datetime
import os
import json
import logging

import boto3

from tabulate import tabulate

from s3backup import sync
from s3backup.clients import local, s3


CONFIG_FILE_PATH = os.path.expanduser('~/.config/s3backup/sync.conf')


def get_client(target):
    if target.startswith('s3://'):
        s3_uri = s3.parse_s3_uri(target)
        s3_client = boto3.client('s3')
        return s3.S3SyncClient(s3_client, s3_uri.bucket, s3_uri.key)
    else:
        return local.LocalSyncClient(target)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--log-level', default='INFO', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'])
    parser.add_argument('--conflicts', default=None, choices=['1', '2', 'ignore'])

    subparsers = parser.add_subparsers(dest='command')
    subparsers.add_parser('sync')

    ls_parser = subparsers.add_parser('ls')
    ls_parser.add_argument('path')

    args = parser.parse_args()

    if args.log_level == 'DEBUG':
        log_format = '%(levelname)s:%(module)s:%(lineno)s %(message)s'
    else:
        log_format = '%(message)s'

    logging.basicConfig(format=log_format, level=args.log_level)

    # shut boto up
    logging.getLogger('boto3').setLevel(logging.CRITICAL)
    logging.getLogger('botocore').setLevel(logging.CRITICAL)
    logging.getLogger('nose').setLevel(logging.CRITICAL)
    logging.getLogger('s3transfer').setLevel(logging.CRITICAL)

    logger = logging.getLogger(__name__)
    logger.setLevel(args.log_level)

    config = get_config()

    if args.command == 'sync':
        sync_command(args, config, logger)
    elif args.command == 'ls':
        ls_command(args, config, logger)
    else:
        parser.print_help()


def get_config():
    if not os.path.exists(CONFIG_FILE_PATH):
        raise ValueError('Expected Config file:', CONFIG_FILE_PATH)

    with open(CONFIG_FILE_PATH, 'r') as fp:
        config = json.load(fp)
    return config


def get_clients(entry):
    target_1 = entry['source']
    target_2 = entry['target']

    # append trailing slashes to prevent incorrect prefix matching on s3
    if not target_1.endswith('/'):
        target_1 += '/'
    if not target_2.endswith('/'):
        target_2 += '/'

    client_1 = get_client(target_1)
    client_2 = get_client(target_2)
    return client_1, client_2


def sync_command(args, config, logger):
    try:
        for entry in config['directories']:
            client_1, client_2 = get_clients(entry)

            logger.info('Syncing %s with %s', client_1.get_uri(), client_2.get_uri())
            sync.sync(client_1, client_2, conflict_choice=args.conflicts)
    except KeyboardInterrupt:
        logger.warning('Quitting due to Keyboard Interrupt...')


def ls_command(args, config, logger):
    path = os.path.expanduser(args.path)
    target = None
    for entry in config['directories']:
        if path in (entry['source'], entry['target']):
            target = entry

    if target is None:
        print('Target specified is not a synced directory')
        return

    client_1, client_2 = get_clients(target)

    keys = set(client_1.index) | set(client_2.index)

    data = []
    for key in sorted(keys):
        entry_1 = client_1.index.get(key, {})
        entry_2 = client_2.index.get(key, {})

        ts_1 = entry_1.get('local_timestamp')
        ts_2 = entry_2.get('local_timestamp')

        if ts_1 is not None:
            data.append((
                key,
                datetime.datetime.utcfromtimestamp(int(ts_1)) if ts_1 is not None else '<deleted>',
                datetime.datetime.utcfromtimestamp(int(ts_2)) if ts_2 is not None else None,
            ))

    print(tabulate(data, headers=['Key', client_1.get_client_name(), client_2.get_client_name()]))


if __name__ == '__main__':
    main()
